{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To fetch data from kaggle\n",
    "!pip install -U kaggle-cli\n",
    "!kg download -u yourusername -p yourpassword -c plant-seedlings-classification  #no single quotes in the username, password and competition name.\n",
    "!unzand ip train.zip\n",
    "!unzip test.zip\n",
    "!unzip sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of transforms goes here\n",
    "\n",
    "Basic = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "BasicScale = transforms.Compose([transforms.Scale(128),\n",
    "                                 transforms.CenterCrop(128),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "BasicAugment = transforms.Compose([transforms.Scale(224),\n",
    "                                   transforms.RandomCrop(128),\n",
    "                                   transforms.RandomHorizontalFlip()])\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "Normalize = transforms.Compose([transforms.ToTensor(),\n",
    "                               normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes\n",
      "['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n"
     ]
    }
   ],
   "source": [
    "VAL_SIZE = 0.1                                    #Validation ratio\n",
    "dtype = torch.FloatTensor                         #dtype\n",
    "NUM_W = 4                                         #Num of Workers\n",
    "PIN = False                                       #Pin Memory\n",
    "B = 16                                             #Batch Size\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    NUM_W = 1\n",
    "    PIN = True\n",
    "\n",
    "#Loaded twice because val may need a diff. transform than train\n",
    "train_dataset = ImageFolder('train', transform=BasicScale)\n",
    "val_dataset = ImageFolder('train', transform=BasicScale) \n",
    "\n",
    "print 'Classes'\n",
    "print train_dataset.classes\n",
    "\n",
    "indices = list(xrange(len(train_dataset)))\n",
    "split = int(np.floor(VAL_SIZE * len(train_dataset)))\n",
    "\n",
    "#shuffling\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "train_len = len(train_idx)\n",
    "val_len = len(val_idx)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=B, sampler=train_sampler, num_workers=NUM_W, pin_memory=PIN)\n",
    "val_loader = DataLoader(val_dataset, batch_size=B, sampler=val_sampler, num_workers=NUM_W, pin_memory=PIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run this cell to get an idea of the probability distribution over all classes\n",
    "ys = []\n",
    "for x, y in train_dataset:\n",
    "    ys.append(y)   \n",
    "\n",
    "plt.hist(ys, linewidth=1.2, edgecolor='black', normed=1)\n",
    "for t in xrange(12):\n",
    "    print '{} occurs {} times'.format(train_dataset.classes[t], ys.count(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=3, stride=1)\n",
    "        self.bn6 = nn.BatchNorm2d(512)\n",
    "        self.linear = nn.Linear(512, 12)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.bn1(F.relu(self.conv1(input), inplace=True))\n",
    "        out = self.bn2(F.relu(self.conv2(out), inplace=True))\n",
    "        out = self.bn3(F.relu(self.conv3(out), inplace=True))\n",
    "        out = self.bn4(F.relu(self.conv4(out), inplace=True))\n",
    "        out = self.bn5(F.relu(self.conv5(out), inplace=True))\n",
    "        out = self.bn6(F.relu(self.conv6(out), inplace=True))\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BasicModel = SimpleCNN().type(dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.Adam(BasicModel.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_val_loss(model):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    for (x, y) in val_loader:\n",
    "        x, y = Variable(x).type(dtype), Variable(y).type(torch.cuda.LongTensor)\n",
    "        scores = model(x)\n",
    "        preds = torch.max(scores, dim=1)[1]\n",
    "        \n",
    "        correct += (torch.sum((preds==y))).type(dtype)\n",
    "        loss = loss_fn(scores, y)\n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "    correct = correct.data.cpu().numpy()[0]\n",
    "    print 'Validation loss is: {}'.format(running_loss)\n",
    "    print 'Got {} / {} correct.'.format(correct, val_len)\n",
    "    return (correct / val_len)\n",
    "\n",
    "def save_model(model):\n",
    "    torch.save(model.state_dict(), 'SimpleCNN.pt')\n",
    "    \n",
    "def load_model(model, file_name):\n",
    "    model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, num_epochs, loss_fn, optimizer, graph=False):\n",
    "    best_model, best_val_acc, best_state_dict = None, 0, None\n",
    "    for epoch in xrange(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for (x, y) in train_loader:\n",
    "            x, y = Variable(x).type(dtype), Variable(y).type(torch.cuda.LongTensor)\n",
    "\n",
    "            scores = model(x)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_fn(scores, y)\n",
    "            running_loss += loss.data[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print 'Loss for epoch {}: {}'.format(epoch, running_loss)\n",
    "        \n",
    "        val_acc = check_val_loss(model)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        \n",
    "    if graph == True:\n",
    "        print 'Implement Graphing of loss here'\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 0: 34.2786741555\n",
      "Validation loss is: 25.7608733475\n",
      "Got 393.0 / 475 correct.\n",
      "Loss for epoch 1: 11.1851177464\n",
      "Validation loss is: 23.8405536711\n",
      "Got 407.0 / 475 correct.\n",
      "Loss for epoch 2: 6.85196298361\n",
      "Validation loss is: 20.3838922996\n",
      "Got 418.0 / 475 correct.\n",
      "Loss for epoch 3: 4.2698225677\n",
      "Validation loss is: 21.9932197575\n",
      "Got 413.0 / 475 correct.\n",
      "Loss for epoch 4: 5.31247013807\n",
      "Validation loss is: 42.1211785376\n",
      "Got 354.0 / 475 correct.\n",
      "Loss for epoch 5: 30.7577182353\n",
      "Validation loss is: 24.6806575954\n",
      "Got 392.0 / 475 correct.\n",
      "Loss for epoch 6: 9.86445197463\n",
      "Validation loss is: 23.622019738\n",
      "Got 391.0 / 475 correct.\n",
      "Loss for epoch 7: 14.9490696266\n",
      "Validation loss is: 21.1600424647\n",
      "Got 406.0 / 475 correct.\n",
      "Loss for epoch 8: 7.11894881725\n",
      "Validation loss is: 27.0791056454\n",
      "Got 400.0 / 475 correct.\n",
      "Loss for epoch 9: 6.49124410748\n",
      "Validation loss is: 21.2499969155\n",
      "Got 406.0 / 475 correct.\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "best_model = train(BasicModel, NUM_EPOCHS, loss_fn, optimizer, graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss is: 21.2005843818\n",
      "Got 418.0 / 475 correct.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Our best model performs like so\\n'\n",
    "check_val_loss(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "ix_to_class = {0:'Black-grass', 1:'Charlock', 2:'Cleavers', 3:'Common Chickweed', 4:'Common wheat', 5:'Fat Hen', \n",
    "               6:'Loose Silky-bent', 7:'Maize', 8:'Scentless Mayweed', 9:'Shepherds Purse', 10:'Small-flowered Cranesbill', \n",
    "               11:'Sugar beet'}\n",
    "\n",
    "def custom_image(model, file_name):\n",
    "    img = Image.open(os.path.join('test', file_name))\n",
    "    img = img.resize((128, 128), Image.BILINEAR)\n",
    "    tensor_img = transforms.ToTensor()\n",
    "    img_var = Variable(tensor_img(img).unsqueeze(0)).type(dtype)\n",
    "    scores = model(img_var)\n",
    "    pred = torch.max(scores, dim=1)[1].data.cpu().numpy()[0]\n",
    "    return ix_to_class[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            file                    species\n",
      "0  0021e90e4.png  Small-flowered Cranesbill\n",
      "1  003d61042.png                    Fat Hen\n",
      "2  007b3da8b.png                 Sugar beet\n",
      "3  0086a6340.png           Common Chickweed\n",
      "4  00c47e980.png                 Sugar beet\n",
      "Alright everything looks good here. Let's save this output to a .csv file\n",
      "Submitting this. Fingers crossed\n",
      "0.86775\n"
     ]
    }
   ],
   "source": [
    "test_df['species'] = test_df['file'].apply(lambda x: custom_image(best_model, x))   #using best_model\n",
    "\n",
    "print test_df.head(5)\n",
    "print \"Alright everything looks good here. Let's save this output to a .csv file\"\n",
    "\n",
    "test_df.to_csv('submit.csv', index=False)\n",
    "\n",
    "print 'Submitting this. Fingers crossed'\n",
    "!kg submit submit.csv -u yourusername -p yourpassword -c plant-seedlings-classification -m \"fingers crossed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
